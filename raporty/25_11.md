# Raport Postępu Prac Projektowych – Etap 1

**Temat:** Opracowanie systemu wizyjnego „Cyber Trener” do analizy biomechaniki ruchu  
**Zespół:** T. Grala, U. Szmit, T. Kot, S. Pokora  
**Data:** 25.11.2025  
**Status:** Zakończony (MVP)

## 1. Cel i Zakres Etapu
Celem pierwszego etapu prac była implementacja **Minimum Viable Product (MVP)** systemu wizyjnego, zdolnego do akwizycji obrazu, detekcji punktów kluczowych sylwetki (pose estimation) oraz wykonywania podstawowych pomiarów geometrycznych w czasie rzeczywistym na standardowym sprzęcie komputerowym (CPU).

## 2. Dobór Technologii (Technology Stack)
Na podstawie analizy dostępnych rozwiązań Open Source, wybrano następujące narzędzia:
* **Język:** Python 3.10 (ze względu na bogaty ekosystem bibliotek Computer Vision).
* **Silnik detekcji:** MediaPipe Pose (model *BlazePose*). Wybrano go ze względu na wysoką wydajność na CPU (30+ FPS) w porównaniu do konkurencyjnego OpenPose (wymagającego GPU).
* **Przetwarzanie obrazu:** OpenCV (`cv2`) do obsługi strumieni wideo i wizualizacji.
* **Obliczenia:** NumPy do wektorowych operacji matematycznych.

## 3. Realizacja Programowa (Implementacja)
Zrealizowano system o architekturze modułowej, składający się z trzech głównych komponentów:

### A. Moduł Percepcji (`core/pose_detector.py`)
Zaimplementowano klasę wrapper dla modelu MediaPipe.
* **Konfiguracja:** Zastosowano `model_complexity=2` (najwyższa dokładność) przy obniżonym progu detekcji (`min_detection_confidence=0.3`), co znacząco poprawiło stabilność wykrywania sylwetki w trudnych warunkach oświetleniowych.

### B. Moduł Algorytmiczny (`core/algorithm.py`) – *Warstwa Autorska*
Zgodnie z wymaganiami projektowymi, zaimplementowano **autorskie funkcje niskopoziomowe**:
1.  **Geometria 2D:** Opracowano funkcję obliczania kąta w stawie na podstawie rzutu 2D (płaszczyzna obrazu) z wykorzystaniem funkcji `atan2`. Zrezygnowano z analizy 3D (oś Z) ze względu na wysoki poziom szumu w głębokości przy pojedynczej kamerze RGB.
2.  **Filtracja Sygnału:** Zaimplementowano filtr wykładniczy (**Exponential Moving Average - EMA**) dla wartości kątowych.
    $$y_t = \alpha \cdot x_t + (1-\alpha) \cdot y_{t-1}$$
    Dobrano współczynnik $\alpha = 0.15$, co pozwoliło na skuteczną eliminację zjawiska drgania punktów (jitter) przy zachowaniu responsywności.

### C. Logika Biznesowa i Wizualizacja (`main.py`, `ui/visualizer.py`)
Stworzono pętlę główną realizującą logikę "Wirtualnego Trenera". System:
* Weryfikuje widoczność kluczowych punktów (parametr `visibility` > 0.5) przed wykonaniem obliczeń.
* Dokonuje klasyfikacji ułożenia kończyny (np. "Prosta ręka" vs "Zgięta") na podstawie progów kątowych.
* Wyświetla wyniki i komunikaty bezpośrednio na klatce wideo.

## 4. Wnioski i Wyniki Testów
Przeprowadzone testy na materiale wideo (`20251125-1733-*.mp4`) wykazały:
1.  **Stabilność:** Zastosowanie filtru EMA wyeliminowało skokowe zmiany wartości kątów.
2.  **Odporność:** Zwiększenie złożoności modelu (`model_complexity=2`) pozwoliło na poprawne śledzenie sylwetki przy szybkich ruchach i obrotach bokiem.
3.  **Ograniczenia:** System jest wrażliwy na niski kontrast (np. ciemna odzież na ciemnym tle), co wymaga zapewnienia odpowiedniego oświetlenia sceny.

## 5. Plan Dalszych Prac (Etap 2)
* Implementacja obsługi wielowątkowości (`threading`) dla płynnego pobierania obrazu z dwóch kamer (lokalna + IP Webcam).
* Opracowanie logiki łączenia danych z dwóch widoków (front + bok) dla pełnej oceny ćwiczenia (np. przysiadu).